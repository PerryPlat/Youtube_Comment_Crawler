{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube 댓글 Crawling\n",
    "\n",
    "### 작성자 : 장동현\n",
    "### 수정일 : 2022년 9월 13일 화요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "def check_comment_count_is_zero(html_source, css_selector):\n",
    "    is_comment_count_zero = False\n",
    "    \n",
    "    soup = BeautifulSoup(html_source, 'lxml')\n",
    "    \n",
    "    datas = soup.select(css_selector)\n",
    "    \n",
    "    if len(datas) > 0:\n",
    "        comment_count_data = datas[0]\n",
    "        \n",
    "        if comment_count_data.text == \"댓글 0개\":\n",
    "            is_comment_count_zero = True\n",
    "            \n",
    "    return is_comment_count_zero\n",
    "\n",
    "\n",
    "def scroll(driver, height=700):\n",
    "    driver.execute_script(f\"window.scrollTo(0, {height});\")\n",
    "\n",
    "\n",
    "\n",
    "def scroll_page(driver):\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(3.0)\n",
    "        \n",
    "        \n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        \n",
    "        if new_page_height == last_page_height:\n",
    "            break\n",
    "            \n",
    "        last_page_height = new_page_height\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_url_title_in_html_source(html_source, css_selector):\n",
    "    titles, urls = [], []\n",
    "    \n",
    "    soup = BeautifulSoup(html_source, 'lxml')\n",
    "    \n",
    "    datas = soup.select(css_selector)\n",
    "    \n",
    "    for data in datas:\n",
    "        title = data.text.replace('\\n', '')\n",
    "        url = \"https://www.youtube.com\" + data.get('href')\n",
    "        \n",
    "        titles.append(title)\n",
    "        urls.append(url)\n",
    "        \n",
    "    return titles, urls\n",
    "\n",
    "\n",
    "def divide_watch_shorts(titles, urls):\n",
    "    watch_url, shorts_url = [], []\n",
    "    \n",
    "    for title, url in zip(titles, urls):\n",
    "        url_type = url.split(\"/\")[3].split(\"?\")[0]\n",
    "        \n",
    "        if url_type == \"watch\":\n",
    "            watch_url.append({\n",
    "                \"title\": title, \n",
    "                \"url\": url\n",
    "            })\n",
    "        elif url_type == \"watch\":\n",
    "            shorts_url.append({\n",
    "                \"title\": title, \n",
    "                \"url\": url\n",
    "            })\n",
    "            \n",
    "    return watch_url, shorts_url\n",
    "        \n",
    "\n",
    "\n",
    "def get_urls_from_youtube_with_keyword(keyword):\n",
    "    \n",
    "    search_keyword_encode = requests.utils.quote(keyword)\n",
    "    \n",
    "    url = \"https://www.youtube.com/results?search_query=\" + search_keyword_encode\n",
    "    \n",
    "    driver = wd.Chrome(executable_path=\"/Users/donghyunjang/PythonHome/chromedriver_105\")\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    driver = scroll_page(driver=driver)\n",
    "        \n",
    "    html_source = driver.page_source\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    css_selector = \"ytd-video-renderer.style-scope.ytd-item-section-renderer > div#dismissible > div.text-wrapper.style-scope.ytd-video-renderer > div#meta > div#title-wrapper > h3.title-and-badge.style-scope.ytd-video-renderer > a#video-title\"\n",
    "    \n",
    "    titles, urls = get_url_title_in_html_source(\n",
    "        html_source=html_source,\n",
    "        css_selector=css_selector\n",
    "    )\n",
    "        \n",
    "    return titles, urls\n",
    "\n",
    "\n",
    "def get_channel_video_url_list(channel_url):\n",
    "    titles = []\n",
    "    urls = []\n",
    "    \n",
    "    driver = wd.Chrome(executable_path=\"/Users/donghyunjang/PythonHome/chromedriver_105\")\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    driver.get(channel_url)\n",
    "    \n",
    "    driver = scroll_page(driver=driver)\n",
    "        \n",
    "    html_source = driver.page_source\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    url_title_css_selector = \"ytd-grid-video-renderer.style-scope.ytd-grid-renderer > div#dismissible > div#details > div#meta > h3.style-scope.ytd-grid-video-renderer > a#video-title\"\n",
    "    \n",
    "    titles, urls = get_url_title_in_html_source(\n",
    "        html_source=html_source, \n",
    "        css_selector=url_title_css_selector\n",
    "    )\n",
    "        \n",
    "    return titles, urls\n",
    "\n",
    "def crawl_youtube_page_html_sources(urls):\n",
    "    html_sources = []\n",
    "\n",
    "    for idx in range(len(urls)):\n",
    "        driver = wd.Chrome(executable_path=\"/Users/donghyunjang/PythonHome/chromedriver_105\")\n",
    "        driver.maximize_window()\n",
    "        driver.get(urls[idx]['url'])\n",
    "        \n",
    "        time.sleep(3.0)\n",
    "        \n",
    "        scroll(driver)\n",
    "        \n",
    "        comment_css_selector = \"ytd-comments-header-renderer.style-scope.ytd-item-section-renderer > div#title > h2#count > yt-formatted-string.count-text.style-scope.ytd-comments-header-renderer\"\n",
    "        \n",
    "        WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.CSS_SELECTOR, comment_css_selector)))\n",
    "        \n",
    "        html_source = driver.page_source\n",
    "        \n",
    "        is_comment_count_zero = check_comment_count_is_zero(\n",
    "            html_source=html_source, css_selector=comment_css_selector\n",
    "        )\n",
    "        \n",
    "        if not is_comment_count_zero:\n",
    "            driver = scroll_page(driver=driver)\n",
    "\n",
    "        html_source = driver.page_source\n",
    "        html_sources.append(html_source)\n",
    "\n",
    "        driver.quit()\n",
    "        \n",
    "    return html_sources\n",
    "\n",
    "\n",
    "def post_processing_text(text):\n",
    "    return text.replace('\\n', '').replace('\\t', '').replace('                ','') if text is not None else \"\"\n",
    "\n",
    "\n",
    "def pack_space(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "\n",
    "def get_user_IDs_and_comments(url_dict, video_type, html_source):\n",
    "    comment_crawl_result_dict = {\n",
    "        \"title\": url_dict['title'], \n",
    "        \"video_url\": url_dict['url'], \"video_type\": video_type,\n",
    "        \"comment\": []\n",
    "    }\n",
    "    \n",
    "    comment_id_css_selector = \"ytd-comment-renderer#comment > div#body > div#main > div#header > div#header-author > h3.style-scope.ytd-comment-renderer > a#author-text\"\n",
    "    comment_text_css_selector = \"ytd-comment-renderer#comment > div#body > div#main > div#comment-content > ytd-expander#expander > div#content > yt-formatted-string#content-text\"\n",
    "    soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "\n",
    "    youtube_user_ID_list = soup.select(comment_id_css_selector)\n",
    "    youtube_comment_list = soup.select(comment_text_css_selector)\n",
    "\n",
    "    for youtube_user_id, youtube_comment in zip(youtube_user_ID_list, youtube_comment_list):\n",
    "        user_id = pack_space(text=post_processing_text(text=youtube_user_id.text))\n",
    "        comment = post_processing_text(text=youtube_comment.text)\n",
    "\n",
    "        comment_data_dict = {\"id\":user_id, \"comment\":comment}\n",
    "        \n",
    "        comment_crawl_result_dict['comment'].append(comment_data_dict)\n",
    "    \n",
    "    return comment_crawl_result_dict\n",
    "\n",
    "\n",
    "def convert_crawl_result_dict_to_csv(crawl_result_dict):\n",
    "    title = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…《\\》]', '', crawl_result_dict['title'])\n",
    "    \n",
    "    temp_df = pd.DataFrame(crawl_result_dict['comment'])\n",
    "    \n",
    "    temp_df = temp_df[['id', 'comment']]\n",
    "    \n",
    "    temp_df.to_csv(f\"{title}.csv\", index=False)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 예시 - 키워드 검색 > 동영상 목록 url 크롤링 > 각 영상별 결과 dictionary 생성 > dic to csv 저장\n",
    "### > 현재는 watch url 만 지원 \n",
    "### > 각 결과는 동영상 이름으로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawling_result_list = []\n",
    "\n",
    "titles, urls = get_urls_from_youtube_with_keyword(\n",
    "    keyword = \"레고\"\n",
    ")\n",
    "\n",
    "\n",
    "watch_url, shorts_url = divide_watch_shorts(titles, urls)\n",
    "\n",
    "watch_url = watch_url[:1]\n",
    "\n",
    "# watch_url\n",
    "html_sources = crawl_youtube_page_html_sources(watch_url)\n",
    "\n",
    "for url_dict, html_source in zip(watch_url, html_sources):\n",
    "    crawl_result = get_user_IDs_and_comments(\n",
    "        url_dict=url_dict, \n",
    "        video_type=\"watch\", \n",
    "        html_source=html_source\n",
    "    )\n",
    "    \n",
    "    crawling_result_list.append(crawl_result)\n",
    "\n",
    "\n",
    "for crawl_result in crawling_result_list:\n",
    "    convert_crawl_result_dict_to_csv(\n",
    "        crawl_result_dict=crawl_result\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 예시 - 채널 이동 > 동영상 목록 url 크롤링 > 각 영상별 결과 dictionary 생성 > dic to csv 저장\n",
    "### > 현재는 watch url 만 지원 \n",
    "### > 각 결과는 동영상 이름으로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawling_result_list = []\n",
    "\n",
    "titles, urls = get_channel_video_url_list(\n",
    "    channel_url=\"https://www.youtube.com/c/%EA%BE%B8%EC%82%90KUPI/videos\"\n",
    ")\n",
    "\n",
    "\n",
    "watch_url, shorts_url = divide_watch_shorts(titles, urls)\n",
    "\n",
    "watch_url = watch_url[:1]\n",
    "\n",
    "# watch_url\n",
    "html_sources = crawl_youtube_page_html_sources(watch_url)\n",
    "\n",
    "for url_dict, html_source in zip(watch_url, html_sources):\n",
    "    crawl_result = get_user_IDs_and_comments(\n",
    "        url_dict=url_dict, \n",
    "        video_type=\"watch\", \n",
    "        html_source=html_source\n",
    "    )\n",
    "    \n",
    "    crawling_result_list.append(crawl_result)\n",
    "\n",
    "\n",
    "for crawl_result in crawling_result_list:\n",
    "    convert_crawl_result_dict_to_csv(\n",
    "        crawl_result_dict=crawl_result\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 예시 - 특정 동영상만 크롤링 > 결과 dictionary 생성 > dic to csv 저장\n",
    "### > 현재는 watch url 만 지원 \n",
    "### > 각 결과는 동영상 이름으로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "url = \"\"\n",
    "\n",
    "watch_url = [{\n",
    "    \"title\": title, \n",
    "    \"url\": url\n",
    "}]\n",
    "\n",
    "# watch_url\n",
    "html_sources = crawl_youtube_page_html_sources(watch_url)\n",
    "\n",
    "for url_dict, html_source in zip(watch_url, html_sources):\n",
    "    crawl_result = get_user_IDs_and_comments(\n",
    "        url_dict=url_dict, \n",
    "        video_type=\"watch\", \n",
    "        html_source=html_source\n",
    "    )\n",
    "    \n",
    "    crawling_result_list.append(crawl_result)\n",
    "\n",
    "\n",
    "for crawl_result in crawling_result_list:\n",
    "    convert_crawl_result_dict_to_csv(\n",
    "        crawl_result_dict=crawl_result\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
